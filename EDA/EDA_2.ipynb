{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitckidscondaeba5e997e95d433391cca1cee29345d7",
   "display_name": "Python 3.7.6 64-bit ('ckids': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA / data cleanup part 2\n",
    "Attempt to add categories for food outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import wordcloud\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import ast\n",
    "import re\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ig = pd.read_csv(r'data\\df_ig.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(15210, 56)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df_ig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                 file_name                                            descrip  \\\n0  2020-03-09_15-23-42_UTC  Sorrel OC by @slavontherocks done by @neptunea...   \n1  2020-03-09_15-24-07_UTC  Green juice going out this morning to my sis @...   \n2  2020-03-09_15-24-51_UTC  Herkesin memleketi cennettir kendine. #kale #t...   \n\n                                            hashtags comments_disabled  \\\n0  ['goku', 'vegeta', 'gohan', 'trunks', 'cabba',...             False   \n1  ['NettesNaturalJuice', 'GreenJuice', 'Kale', '...             False   \n2  ['kale', 'tillo', 'mavi', 'kƒ±rmƒ±zƒ±', 'doƒüa', '...             False   \n\n   __typename            id  \\\n0  GraphImage  2.261169e+18   \n1  GraphImage  2.261168e+18   \n2  GraphImage  2.261167e+18   \n\n                               edge_media_to_caption    shortcode  \\\n0  {'edges': [{'node': {'text': 'Planted the #kal...  B9hSO10JAC8   \n1  {'edges': [{'node': {'text': \"This post has be...  B9hSHwVgiG6   \n2  {'edges': [{'node': {'text': 'E≈üsiz Lezzetler ...  B9hR3yqFmPX   \n\n  edge_media_to_comment  taken_at_timestamp  ... is_published title  \\\n0          {'count': 0}        1.583772e+09  ...          NaN   NaN   \n1          {'count': 0}        1.583772e+09  ...          NaN   NaN   \n2          {'count': 0}        1.583772e+09  ...          NaN   NaN   \n\n  video_duration edge_sidecar_to_children        username location_name  \\\n0            NaN                      NaN         derbyka           NaN   \n1            NaN                      NaN  saltsugarspice           NaN   \n2            NaN                      NaN  akropol_bistro    Siirt Kale   \n\n                                       location_desc Unnamed: 0.1  \\\n0                                                NaN          NaN   \n1                                                NaN          NaN   \n2  Siirt Kale\\nhttps://maps.google.com/maps?q=37....          NaN   \n\n  Unnamed: 0.1.1            timestamp  \n0            NaN  2020-03-09 16:45:32  \n1            NaN  2020-03-09 16:44:34  \n2            NaN  2020-03-09 16:42:23  \n\n[3 rows x 56 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>descrip</th>\n      <th>hashtags</th>\n      <th>comments_disabled</th>\n      <th>__typename</th>\n      <th>id</th>\n      <th>edge_media_to_caption</th>\n      <th>shortcode</th>\n      <th>edge_media_to_comment</th>\n      <th>taken_at_timestamp</th>\n      <th>...</th>\n      <th>is_published</th>\n      <th>title</th>\n      <th>video_duration</th>\n      <th>edge_sidecar_to_children</th>\n      <th>username</th>\n      <th>location_name</th>\n      <th>location_desc</th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0.1.1</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-03-09_15-23-42_UTC</td>\n      <td>Sorrel OC by @slavontherocks done by @neptunea...</td>\n      <td>['goku', 'vegeta', 'gohan', 'trunks', 'cabba',...</td>\n      <td>False</td>\n      <td>GraphImage</td>\n      <td>2.261169e+18</td>\n      <td>{'edges': [{'node': {'text': 'Planted the #kal...</td>\n      <td>B9hSO10JAC8</td>\n      <td>{'count': 0}</td>\n      <td>1.583772e+09</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>derbyka</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020-03-09 16:45:32</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-03-09_15-24-07_UTC</td>\n      <td>Green juice going out this morning to my sis @...</td>\n      <td>['NettesNaturalJuice', 'GreenJuice', 'Kale', '...</td>\n      <td>False</td>\n      <td>GraphImage</td>\n      <td>2.261168e+18</td>\n      <td>{'edges': [{'node': {'text': \"This post has be...</td>\n      <td>B9hSHwVgiG6</td>\n      <td>{'count': 0}</td>\n      <td>1.583772e+09</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>saltsugarspice</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020-03-09 16:44:34</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-03-09_15-24-51_UTC</td>\n      <td>Herkesin memleketi cennettir kendine. #kale #t...</td>\n      <td>['kale', 'tillo', 'mavi', 'kƒ±rmƒ±zƒ±', 'doƒüa', '...</td>\n      <td>False</td>\n      <td>GraphImage</td>\n      <td>2.261167e+18</td>\n      <td>{'edges': [{'node': {'text': 'E≈üsiz Lezzetler ...</td>\n      <td>B9hR3yqFmPX</td>\n      <td>{'count': 0}</td>\n      <td>1.583772e+09</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>akropol_bistro</td>\n      <td>Siirt Kale</td>\n      <td>Siirt Kale\\nhttps://maps.google.com/maps?q=37....</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020-03-09 16:42:23</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows √ó 56 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df_ig.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ig.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # count missing values\n",
    "# df_ig.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing file names\n",
    "df_ig = df_ig.dropna(subset=['file_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ig2 = df_ig[[\"file_name\", \"timestamp\", \"hashtags\", \"descrip\", \"accessibility_caption\", \"username\", \"owner\", \"display_url\", \"id\", \"shortcode\", \"is_ad\", \"has_ranked_comments\", \"location\", \"location_name\", \"location_desc\" ]]\n",
    "df_ig2 = df_ig[[\"file_name\", \"timestamp\", \"hashtags\", \"descrip\", \"accessibility_caption\", \"username\", \"owner\", \"display_url\", \"id\", \"shortcode\", \"is_ad\", \"has_ranked_comments\", \"location\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total shape: (15206, 13)\nfile_name                    0\ntimestamp                 4846\nhashtags                     4\ndescrip                      4\naccessibility_caption     5598\nusername                 10234\nowner                     4846\ndisplay_url               4846\nid                        4846\nshortcode                 4846\nis_ad                     4846\nhas_ranked_comments       4846\nlocation                 12210\ndtype: int64\n"
    }
   ],
   "source": [
    "print(\"Total shape:\", df_ig2.shape)\n",
    "print(df_ig2.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Of the 15206 posts, 2996 have location data.\n"
    }
   ],
   "source": [
    "# Running count of loc data\n",
    "print(f\"Of the {df_ig2.shape[0]} posts, {df_ig2['location'].notnull().sum()} have location data.\")\n",
    "# print(f\"Of the {df_ig2.shape[0]} posts, {df_ig2['location_name'].notnull().sum()} have location_name data.\")\n",
    "\n",
    "# print(f\"Of the {df_ig2.shape[0]} posts, {df_ig2['location'].isnull().sum()} do not have location data.\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # how many have both location and/or location_name data? do they intersect?\n",
    "\n",
    "withloc_df = df_ig2[df_ig2['location'].notnull()]\n",
    "# withlocname_df = df_ig2[df_ig2['location_name'].notnull()]\n",
    "\n",
    "# withloc_df['all_loc_info'] = withloc_df['location']\n",
    "# withlocname_df['all_loc_info'] = withlocname_df['location_name']\n",
    "# bothloc_df = pd.merge(withloc_df, withlocname_df, how='inner', on=['all_loc_info'])\n",
    "# print(bothloc_df.shape)\n",
    "# # results show NO common rows have both location and location_name data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert location field to dict\n",
    "# IF the location_name field is NaN, populate with 'name' value from location dict\n",
    "\n",
    "withloc_df['location'] = withloc_df['location'].apply(lambda x: ast.literal_eval(x) if x is not None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the value assoc with 'name'\n",
    "\n",
    "def getname(d):\n",
    "    return d[\"name\"]\n",
    "\n",
    "withloc_df['loc_name_2'] = withloc_df['location'].apply(getname)\n",
    "withloc_df['loc_name_2'] = withloc_df['loc_name_2'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# withloc_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_names = withloc_df['loc_name_2']\n",
    "location_names.to_csv('location_names.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(4962, 2)\n"
    }
   ],
   "source": [
    "## add an outlet category row for those posts with locations\n",
    "categories = pd.read_csv(r\"data\\2014_outlet_categories.csv\", index_col=0)\n",
    "categories.rename(columns={\"shop_name\": \"location_name\", \"type\": \"category\"}, inplace=True)\n",
    "categories['category']= categories['category'].str.replace(\"Burgers\", \"Fast Food\")\n",
    "categories.drop_duplicates(inplace=True)\n",
    "categories.dropna(inplace=True)\n",
    "print(categories.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['Fast Food', 'French', 'Desserts', 'Sandwiches', 'Ice Cream',\n       'Street Food', 'Bakery', 'Fried Chicken', 'Tacos', 'Caribbean',\n       'Latin American', 'Mexican', 'Japanese', 'Pizza', 'South American',\n       'American', 'BBQ', 'Seafood', 'Asian', 'Coffee Shop', 'Chinese',\n       'Mediterranean', 'Indian', 'Korean', 'Juice Bar', 'Food', 'Donuts',\n       'Italian', 'Diner', 'Greek', 'Sushi', 'Hot Dogs', 'Arepas',\n       'Brewery', 'Bagels', 'Burritos', 'Snacks', 'Cupcakes', 'Wings',\n       'New American', 'Eastern European', 'Thai', 'Dim Sum', 'Spanish',\n       'Cuban', 'Argentinian', 'Steakhouse', 'Brazilian', 'Ethiopian',\n       'Tea Room', 'Gastropub', 'African', 'Australian', 'Middle Eastern',\n       'Peruvian', 'Salad', 'Vietnamese', 'Tapas', 'Moroccan', 'Winery',\n       'Gluten-free', 'Dumplings', 'Swiss', 'Falafel', 'German', 'Soup',\n       'Paella', 'Malaysian', 'Filipino', 'Indonesian',\n       'Molecular Gastronomy', 'Mac & Cheese'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "categories['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2770\n"
    }
   ],
   "source": [
    "withlocname = df_ig2[df_ig2['location_name'].notnull()]\n",
    "\n",
    "# how many unique food outlets?\n",
    "print(withlocname['location_name'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(45, 16)\n"
    }
   ],
   "source": [
    "# naive join (without any fuzzy matching)\n",
    "match1 = withlocname.merge(categories, on=['location_name'])\n",
    "print(match1.shape)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                  file_name            timestamp  \\\n26  2020-02-23_04-47-01_UTC                  NaN   \n11  2020-02-18_19-52-48_UTC  2020-02-21 19:15:24   \n16  2020-02-23_04-18-50_UTC                  NaN   \n23  2020-03-10_21-23-26_UTC  2020-03-10 20:49:05   \n39  2020-02-22_04-00-00_UTC                  NaN   \n\n                                             hashtags  \\\n26  ['burgerking', 'bk', 'whopper', 'burger', 'bur...   \n11                                                 []   \n16  ['In', 'inandoutburger', 'burger', 'keizeroreg...   \n23  ['burguerking', 'hamburguesas', 'hamburguer', ...   \n39                                                 []   \n\n                                              descrip  \\\n26  Late night Bacon & Cheese Whopper & Fries.\\nüçî\\...   \n11                                   Animal style ü§™\\n   \n16  Just chillin. üòé\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n#In-N...   \n23  Burguer King me paga millones, olvidate.\\n.\\nP...   \n39  Back from the groomers and looking like fluffe...   \n\n      accessibility_caption    username  \\\n26                      NaN         NaN   \n11  Image may contain: food    pound.mx   \n16                      NaN         NaN   \n23  Image may contain: food  drayuheats   \n39                      NaN         NaN   \n\n                                                owner  \\\n26                                                NaN   \n11  {'id': '7580812187', 'is_verified': False, 'pr...   \n16                                                NaN   \n23  {'id': '2122526598', 'is_verified': False, 'pr...   \n39                                                NaN   \n\n                                          display_url            id  \\\n26                                                NaN           NaN   \n11  https://scontent-mia3-2.cdninstagram.com/v/t51...  2.248923e+18   \n16                                                NaN           NaN   \n23  https://scontent-mia3-2.cdninstagram.com/v/t51...  2.262016e+18   \n39                                                NaN           NaN   \n\n      shortcode  is_ad has_ranked_comments  \\\n26          NaN    NaN                 NaN   \n11  B81x3J_He64  False               False   \n16          NaN    NaN                 NaN   \n23  B9kS5hQH3PK  False               False   \n39          NaN    NaN                 NaN   \n\n                                             location    location_name  \\\n26                                                NaN      Burger King   \n11                                                NaN  In-N-Out Burger   \n16                                                NaN  In-N-Out Burger   \n23  {'id': 673643029416527, 'name': 'Krispy Krunch...      Burger King   \n39                                                NaN            Hachi   \n\n                                        location_desc   category  \n26  Burger King\\nhttps://maps.google.com/maps?q=36...  Fast Food  \n11  In-N-Out Burger\\nhttps://maps.google.com/maps?...  Fast Food  \n16  In-N-Out Burger\\nhttps://maps.google.com/maps?...  Fast Food  \n23  Burger King\\nhttps://maps.google.com/maps?q=-3...  Fast Food  \n39  Hachi\\nhttps://maps.google.com/maps?q=-37.8399...      Sushi  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>timestamp</th>\n      <th>hashtags</th>\n      <th>descrip</th>\n      <th>accessibility_caption</th>\n      <th>username</th>\n      <th>owner</th>\n      <th>display_url</th>\n      <th>id</th>\n      <th>shortcode</th>\n      <th>is_ad</th>\n      <th>has_ranked_comments</th>\n      <th>location</th>\n      <th>location_name</th>\n      <th>location_desc</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>26</th>\n      <td>2020-02-23_04-47-01_UTC</td>\n      <td>NaN</td>\n      <td>['burgerking', 'bk', 'whopper', 'burger', 'bur...</td>\n      <td>Late night Bacon &amp; Cheese Whopper &amp; Fries.\\nüçî\\...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Burger King</td>\n      <td>Burger King\\nhttps://maps.google.com/maps?q=36...</td>\n      <td>Fast Food</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2020-02-18_19-52-48_UTC</td>\n      <td>2020-02-21 19:15:24</td>\n      <td>[]</td>\n      <td>Animal style ü§™\\n</td>\n      <td>Image may contain: food</td>\n      <td>pound.mx</td>\n      <td>{'id': '7580812187', 'is_verified': False, 'pr...</td>\n      <td>https://scontent-mia3-2.cdninstagram.com/v/t51...</td>\n      <td>2.248923e+18</td>\n      <td>B81x3J_He64</td>\n      <td>False</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>In-N-Out Burger</td>\n      <td>In-N-Out Burger\\nhttps://maps.google.com/maps?...</td>\n      <td>Fast Food</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2020-02-23_04-18-50_UTC</td>\n      <td>NaN</td>\n      <td>['In', 'inandoutburger', 'burger', 'keizeroreg...</td>\n      <td>Just chillin. üòé\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n#In-N...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>In-N-Out Burger</td>\n      <td>In-N-Out Burger\\nhttps://maps.google.com/maps?...</td>\n      <td>Fast Food</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>2020-03-10_21-23-26_UTC</td>\n      <td>2020-03-10 20:49:05</td>\n      <td>['burguerking', 'hamburguesas', 'hamburguer', ...</td>\n      <td>Burguer King me paga millones, olvidate.\\n.\\nP...</td>\n      <td>Image may contain: food</td>\n      <td>drayuheats</td>\n      <td>{'id': '2122526598', 'is_verified': False, 'pr...</td>\n      <td>https://scontent-mia3-2.cdninstagram.com/v/t51...</td>\n      <td>2.262016e+18</td>\n      <td>B9kS5hQH3PK</td>\n      <td>False</td>\n      <td>False</td>\n      <td>{'id': 673643029416527, 'name': 'Krispy Krunch...</td>\n      <td>Burger King</td>\n      <td>Burger King\\nhttps://maps.google.com/maps?q=-3...</td>\n      <td>Fast Food</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>2020-02-22_04-00-00_UTC</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>Back from the groomers and looking like fluffe...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Hachi</td>\n      <td>Hachi\\nhttps://maps.google.com/maps?q=-37.8399...</td>\n      <td>Sushi</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "match1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(2770,)"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "unique_names = pd.Series(withlocname['location_name'].unique())\n",
    "unique_names = unique_names.sort_values(ascending=True)\n",
    "print(unique_names.shape)\n",
    "unique_names.to_csv('unique_names.csv', index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: \n",
    "- Clean the unique names (remove double quotes; standardize/combine names using fuzzywuzzy or pyenchant)\n",
    "- "
   ]
  }
 ]
}